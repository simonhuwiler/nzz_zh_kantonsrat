{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract PDF\n",
    "This Script tries to detect, when someone was speaking and extracts it as raw as possible. Creates a json for each pdf.  \n",
    "\n",
    "Logic: Find Text in italic at line start. Means: New person is speaking. Copy everything until next italic or bold text.\n",
    "\n",
    "Tests:\n",
    "* Empty italic Line before Name: ../export/Files/2021-09-27-17fa216f98fd4d38afd5afb53743ec65-332.pdf, p 18\n",
    "* Multiline-Name: 2021-08-30-eabdc84b3d6b4153ae371fcdbdab6b68-332.pdf, p 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(f):\n",
    "\n",
    "    textbuf = \"\"\n",
    "    pagebuf = []\n",
    "    reading = False\n",
    "    skip_until_bold = False\n",
    "\n",
    "    paragraphs = []\n",
    "\n",
    "    fakes = ['Detailberatung', 'Titel und Ingress', 'I. und II.', 'III.', 'Abstimmung', 'IV.',\n",
    "    'Schlussabstimmung']\n",
    "\n",
    "    pages = extract_pages(f)\n",
    "\n",
    "    i = 0\n",
    "    for page_layout in pages:\n",
    "        i += 1\n",
    "\n",
    "        for iParagraph, element in enumerate(page_layout):\n",
    "            if isinstance(element, LTTextContainer):\n",
    "\n",
    "                #print(\"[%s]\" % element.get_text())\n",
    "\n",
    "                lines = list(element)\n",
    "\n",
    "                # Before going into detection, fix new page problem:\n",
    "                # On every new page there is a page number. Sometimes there is a empty line between\n",
    "                # So do: Remove empty lines if first \"text\" line does NOT contains italic\n",
    "                #iLine[0]\n",
    "                if iParagraph == 0:\n",
    "\n",
    "                    # Remove first line (Page Number)\n",
    "                    lines.pop(0)\n",
    "\n",
    "                    # Find first \"text\" line and remove others above\n",
    "                    index = -1\n",
    "                    for iLine, l in enumerate(lines):\n",
    "                        if len(l.get_text().strip()) > 0:\n",
    "                            # Is Text Line!\n",
    "                            index = iLine\n",
    "                            break\n",
    "\n",
    "                    # If index >= 0, pop until text line\n",
    "                    if index >= 0:\n",
    "                        for j in range(0, index):\n",
    "                            lines.pop(0)\n",
    "\n",
    "                # Now go line by line and find kings and queens.\n",
    "                for iLine, text_line in enumerate(lines):\n",
    "\n",
    "                    text = text_line.get_text()\n",
    "                    line_above = lines[iLine - 1]\n",
    "\n",
    "                    first_char = list(text_line)[0]\n",
    "\n",
    "                    # Skip everything that contains \"Antworten auf Anfrage\"\n",
    "                    if 'Antworten auf Anfragen' in text:\n",
    "                        skip_until_bold = True\n",
    "\n",
    "                    elif isinstance(first_char, LTChar) and ('bold' in first_char.fontname.lower()):\n",
    "                        skip_until_bold = False\n",
    "\n",
    "                    if skip_until_bold: continue\n",
    "                    \n",
    "                    # Search for Italic. Then it could be a queen\n",
    "                    if isinstance(first_char, LTChar) and ('italic' in first_char.fontname.lower()):\n",
    "                        \n",
    "                        # Stop, if still reading. EXCEPT: Line above was also italic (multilines)\n",
    "                        if (\n",
    "                            (reading and iLine == 0)\n",
    "                            or (iLine > 0 and ( #Multiline check. Line above is italic and empty\n",
    "                                not('italic' in list(lines[iLine - 1])[0].fontname.lower())\n",
    "                                or(list(lines[iLine - 1])[0].get_text().strip() == '')\n",
    "                                )) \n",
    "                        ):\n",
    "                            # Maybe the italic is inline text? Check if Line above was empty line or not existing\n",
    "                            if (\n",
    "                                (iLine == 0)\n",
    "                                or (line_above.get_text().strip() == '') # Inline italic Check\n",
    "                            ):\n",
    "                                paragraphs.append({'t': textbuf, 'p': pagebuf[0] if len(pagebuf) > 0 else i})\n",
    "                                reading = False\n",
    "                                textbuf = \"\"\n",
    "                                pagebuf = []\n",
    "                        \n",
    "                        # \"Fake\" check\n",
    "                        is_fake = False\n",
    "                        for fake in fakes:\n",
    "                            if fake in text:\n",
    "                                is_fake = True\n",
    "                                break\n",
    "                        reading = not is_fake\n",
    "                    \n",
    "                    # Stop Reading if Bold detected\n",
    "                    if isinstance(first_char, LTChar) and ('bold' in first_char.fontname.lower()):\n",
    "                        paragraphs.append({'t': textbuf, 'p': pagebuf[0] if len(pagebuf) > 0 else i})\n",
    "\n",
    "                        reading = False\n",
    "                        textbuf = \"\"\n",
    "                        pagebuf = []\n",
    "\n",
    "                    # Fill Buffer if we are reading\n",
    "                    if reading:\n",
    "                        textbuf += text\n",
    "                        pagebuf.append(i)\n",
    "\n",
    "    # If still reading, add to dict\n",
    "    if reading:\n",
    "        paragraphs.append({'t': textbuf, 'p': pagebuf[0] if len(pagebuf) > 0 else i})\n",
    "\n",
    "\n",
    "    return paragraphs\n",
    "\n",
    "#p = read_pdf('../export/Files/2021-09-27-17fa216f98fd4d38afd5afb53743ec65-332.pdf')\n",
    "\n",
    "#for x in p:\n",
    "#    print(\"----\")\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finito\n"
     ]
    }
   ],
   "source": [
    "# Get all files\n",
    "df = pd.read_csv(Path('../export/dokumente.csv'))\n",
    "\n",
    "# Only \"Protokoll\"\n",
    "df = df[df.dokument_kategorie == 'Protokoll']\n",
    "\n",
    "# Loop file\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    # Create Name\n",
    "    fname = Path('../export/extracts/%s' % row['_filename']).with_suffix('.json')\n",
    "\n",
    "    if not fname.is_file():\n",
    "        #print(fname)\n",
    "        # Parse PDF\n",
    "        paragraphs = read_pdf(Path('../export/Files/') / row['_filename'])\n",
    "\n",
    "        # Save\n",
    "        with open(fname, 'w', encoding='UTF-8') as f:\n",
    "            f.write(json.dumps(paragraphs, ensure_ascii=False))\n",
    "\n",
    "print(\"finito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Traktanden\n",
    "This we need for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all XML and create Dataframe\n",
    "ns = {\n",
    "    's': 'http://www.cmiag.ch/cdws/searchDetailResponse',\n",
    "    'd': 'http://www.cmiag.ch/cdws/SitzungenDetail'\n",
    "    }\n",
    "\n",
    "records = []\n",
    "\n",
    "\n",
    "for f in glob.glob(str(Path('../export/SITZUNGENDETAIL/*.xml'))):\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "\n",
    "\n",
    "    for sitzung in root.findall('.//s:Hit/d:Sitzung', ns):\n",
    "        for traktandum in sitzung.findall('d:Traktanden/d:Traktandum', ns):\n",
    "            edok = sitzung.find('d:Sitzungsdokumente/d:Dokument/d:eDokument', ns)\n",
    "            dok = edok.attrib['ID'] if edok else None\n",
    "\n",
    "            sitzung_start = sitzung.find('d:Datum/d:Start', ns).text if sitzung.find('d:Sitzungsbeginn/d:Start', ns) is None else sitzung.find('d:Sitzungsbeginn/d:Start', ns).text\n",
    "            records.append({\n",
    "                'sitzung': sitzung_start,\n",
    "                'dokument': dok,\n",
    "                'titel': traktandum.find('d:Titel', ns).text,\n",
    "                '_filename': Path(f).stem\n",
    "            })\n",
    "    #break\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "df.to_csv(Path('../export/traktanden.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in p:\n",
    "#    print(\"----\")\n",
    "#    print(x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69dc94fc393d943518fcde1eb0a856b515bbecd136e3dea5800bae48efbead23"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
