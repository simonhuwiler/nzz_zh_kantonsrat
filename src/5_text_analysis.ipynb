{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Und das Wort ist Fleisch geworden\n",
    "* https://textmining.wp.hs-hannover.de/Preprocessing.html\n",
    "* Tagset: https://homepage.ruhr-uni-bochum.de/stephen.berman/Korpuslinguistik/Tagsets-STTS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "from pathlib import Path\n",
    "#import utils\n",
    "from HanTa import HanoverTagger as ht\n",
    "import glob\n",
    "#import ast\n",
    "#import functools\n",
    "#import copy\n",
    "#import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Do once\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize / Tag and store as CSV (only once, then goto: next cell)\n",
    "Store lemmatized and tagged data as json because of performance issues. Loading a csv with (many!) dicts is very slow and like flying from BER...  \n",
    "Split it up to store it on github (max filesize = 100mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votum_raw = pd.read_csv(Path('../export/votum.csv'))\n",
    "\n",
    "# Remove empty texts\n",
    "df_votum_raw = df_votum_raw[df_votum_raw.text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tagging\n",
    "records = []\n",
    "for i, row in df_votum_raw.iterrows():\n",
    "    lemm = nltk.tokenize.word_tokenize(row['text'], language='german')\n",
    "\n",
    "    records.append({\n",
    "        'name': row['name'],\n",
    "        'vorname': row['vorname'],\n",
    "        'partei': row['partei'],\n",
    "        'jahrgang': row['jahrgang'],\n",
    "        'geschlecht': row['geschlecht'],\n",
    "        'funktion': row['funktion'],\n",
    "        'ismember': row['ismember'],\n",
    "        'tags': tagger.tag_sent(lemm, taglevel=1),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finito\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split\n",
    "chunks = 5\n",
    "bucketsize = math.ceil(len(records) / chunks)\n",
    "for i in range(0, chunks):\n",
    "    subrecords = []\n",
    "    for j in range(bucketsize * i, bucketsize * ( i + 1 )):\n",
    "        if j < len(records):\n",
    "            subrecords.append(records[j])\n",
    "\n",
    "    # Store\n",
    "    with open(Path('../export/tags/tag_%s.json' % i), 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(subrecords, ensure_ascii=False))\n",
    "\n",
    "print(\"finito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stemmatized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46521\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for f in glob.glob(str(Path('../export/tags/*.json'))):\n",
    "    records = records + json.load(open(f, 'r', encoding='utf-8'))\n",
    "\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34497\n"
     ]
    }
   ],
   "source": [
    "# Members only, no Presidents\n",
    "r_members = list(filter(lambda x: x['ismember'] == True, records))\n",
    "r_members = list(filter(lambda x: x['funktion'] not in ['Präsidium', '2. Vizepräsidium', '1. Vizepräsidium'], r_members))\n",
    "print(len(r_members))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only Nouns\n",
    "list_m = []\n",
    "list_w = []\n",
    "for r in r_members:\n",
    "    tags = [lemma for (word,lemma,pos) in r['tags'] if pos == \"NN\" or pos == \"NE\"]\n",
    "    if r['geschlecht'] == 'm': list_m = list_m + tags\n",
    "    elif r['geschlecht'] == 'w': list_w = list_w + tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>w</th>\n",
       "      <th>count</th>\n",
       "      <th>geschlecht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Kind</td>\n",
       "      <td>2561</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Sp</td>\n",
       "      <td>1980</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Frau</td>\n",
       "      <td>1631</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mensch</td>\n",
       "      <td>1630</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Grüne</td>\n",
       "      <td>1616</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Arbeit</td>\n",
       "      <td>1521</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Schule</td>\n",
       "      <td>1449</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Ziel</td>\n",
       "      <td>1399</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Herr</td>\n",
       "      <td>4679</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Rat</td>\n",
       "      <td>3720</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Budget</td>\n",
       "      <td>3642</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Mehrheit</td>\n",
       "      <td>3623</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Leute</td>\n",
       "      <td>3424</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Zukunft</td>\n",
       "      <td>3198</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Bund</td>\n",
       "      <td>3116</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Lösung</td>\n",
       "      <td>3109</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         w  count geschlecht\n",
       "9       9      Kind   2561          w\n",
       "20     20        Sp   1980          w\n",
       "31     31      Frau   1631          w\n",
       "32     32    Mensch   1630          w\n",
       "33     33     Grüne   1616          w\n",
       "40     40    Arbeit   1521          w\n",
       "45     45    Schule   1449          w\n",
       "48     48      Ziel   1399          w\n",
       "22     22      Herr   4679          m\n",
       "37     37       Rat   3720          m\n",
       "38     38    Budget   3642          m\n",
       "40     40  Mehrheit   3623          m\n",
       "42     42     Leute   3424          m\n",
       "45     45   Zukunft   3198          m\n",
       "47     47      Bund   3116          m\n",
       "48     48    Lösung   3109          m"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_freqdist_df(l):\n",
    "    fdist = nltk.FreqDist(l)\n",
    "    fdist = fdist.most_common(50)\n",
    "    df_dist = pd.DataFrame(fdist, columns=['w', 'count'])\n",
    "    df_dist.reset_index(drop=False, inplace=True)\n",
    "    return df_dist\n",
    "\n",
    "df_m = get_freqdist_df(list_m)\n",
    "df_m['geschlecht'] = 'm'\n",
    "\n",
    "df_w = get_freqdist_df(list_w)\n",
    "df_w['geschlecht'] = 'w'\n",
    "\n",
    "df_concat = pd.concat([df_w, df_m])\n",
    "\n",
    "# Remove duplicates\n",
    "df_concat = df_concat.drop_duplicates(subset=['w'], keep = False)\n",
    "\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d89f51c21e61334fa582c5b112d16d67677dd53345d4e7223b029a81b433160"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
